# llama
Locally run LLaMa model
